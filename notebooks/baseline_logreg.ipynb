{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# ────────────── standard lib ──────────────\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "import scipy.special"
   ],
   "metadata": {
    "id": "gVlAq_xco66i"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SoIYLTLaoWrl"
   },
   "source": [
    "RUN_ID= \"logreg_bow_baseline\"\n",
    "TRAIN_DATA_PATH= \"data/training_split.csv\"\n",
    "VAL_DATA_PATH= \"data/validation_split.csv\"\n",
    "SEEDS= [13, 21, 42]\n",
    "BATCH_SIZE = 32\n",
    "MAX_FEATURES = 10_000\n",
    "NGRAM_RANGE = (1, 2)\n",
    "C= 1.0\n",
    "MAX_ITER= 300\n",
    "\n",
    "OUT_ROOT = Path(f\"results/{RUN_ID}\")\n",
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "label2id = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "id2label = {v:k for k,v in label2id.items()}\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_DATA_PATH)\n",
    "val_df = pd.read_csv(VAL_DATA_PATH)\n",
    "\n",
    "train_df[\"label\"] = train_df[\"label\"].map(label2id).astype(\"int64\")\n",
    "val_df[\"label\"] = val_df[\"label\"].map(label2id).astype(\"int64\")"
   ],
   "metadata": {
    "id": "wLHLLh-qoglr"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "records = []\n",
    "\n",
    "for seed in SEEDS:\n",
    "    np.random.seed(seed); random.seed(seed)\n",
    "\n",
    "    vectoriser = CountVectorizer(\n",
    "        ngram_range=NGRAM_RANGE,\n",
    "        max_features=MAX_FEATURES\n",
    "    )\n",
    "    X_train = vectoriser.fit_transform(train_df[\"sentence\"])\n",
    "    X_val = vectoriser.transform(val_df[\"sentence\"])\n",
    "\n",
    "    y_train = train_df[\"label\"].values\n",
    "    y_val = val_df[\"label\"].values\n",
    "\n",
    "    model = LogisticRegression(\n",
    "        C=C, max_iter=MAX_ITER,\n",
    "        random_state=seed,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    tic = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    logits = model.decision_function(X_val)\n",
    "    latency = time.time() - tic"
   ],
   "metadata": {
    "id": "qJMXDGEnoj-H"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "proba = scipy.special.softmax(logits, axis=1)\n",
    "p_raw = proba.dot(np.arange(3))\n",
    "p_int = np.argmax(proba, axis=1)\n",
    "y_int = y_val"
   ],
   "metadata": {
    "id": "FqvwqbRgomJ1"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "mae= np.abs(p_raw - y_int).mean()\n",
    "score = 0.5 * (2 - mae)\n",
    "acc= accuracy_score(y_int, p_int)\n",
    "\n",
    "rec = {\n",
    "    \"seed\": seed,\n",
    "    \"score\":        float(score),\n",
    "    \"mae\":          float(mae),\n",
    "    \"accuracy\":     float(acc),\n",
    "    \"latency_sec\":  float(latency),\n",
    "}\n",
    "records.append(rec)\n",
    "\n",
    "out_dir = OUT_ROOT / f\"seed_{seed}\"\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "json.dump(rec, open(out_dir/\"metrics.json\", \"w\"), indent=2)\n",
    "\n",
    "cm = confusion_matrix(y_int, p_int, labels=[0,1,2], normalize=\"true\")\n",
    "fig, ax = plt.subplots(figsize=(3,3))\n",
    "sns.heatmap(cm, annot=True, fmt=\".2f\",\n",
    "            xticklabels=list(label2id), yticklabels=list(label2id), ax=ax)\n",
    "ax.set_title(f\"{RUN_ID} | seed {seed}\")\n",
    "fig.tight_layout(); fig.savefig(out_dir/\"confusion_matrix.png\", dpi=200)\n",
    "plt.close(fig)\n",
    "\n",
    "mis = val_df.iloc[np.where(p_int != y_int)[0]][[\"id\",\"sentence\",\"label\"]]\n",
    "mis[\"pred\"] = [id2label[i] for i in p_int[p_int != y_int]]\n",
    "mis[\"label\"] = mis[\"label\"].map(id2label)\n",
    "mis.to_csv(out_dir/\"misclassified.csv\", index=False)"
   ],
   "metadata": {
    "id": "rhWJoxhroocW"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df_rec = pd.DataFrame(records)\n",
    "\n",
    "n_params_total = model.coef_.size + model.intercept_.size\n",
    "n_params_total_M = round(n_params_total / 1_000_000, 2)\n",
    "\n",
    "agg = {\n",
    "    \"score_mean\": df_rec[\"score\"].mean(),\n",
    "    \"score_std\": df_rec[\"score\"].std(ddof=0),\n",
    "    \"mae_mean\": df_rec[\"mae\"].mean(),\n",
    "    \"mae_std\": df_rec[\"mae\"].std(ddof=0),\n",
    "    \"latency_sec_mean\": df_rec[\"latency_sec\"].mean(),\n",
    "    \"latency_sec_std\": df_rec[\"latency_sec\"].std(ddof=0),\n",
    "    \"params_M_total\": n_params_total_M,\n",
    "    \"params_M_trainable\": n_params_total_M,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"max_features\": MAX_FEATURES\n",
    "}\n",
    "json.dump(agg, open(OUT_ROOT/\"aggregate.json\", \"w\"), indent=2)\n",
    "print(agg)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M4Mp_eZJopQF",
    "outputId": "3ab51616-e029-42cb-edee-d408637eae37"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
